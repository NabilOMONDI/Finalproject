{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from music21 import instrument, note, chord, midi\n",
    "import os\n",
    "import pretty_midi\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pretty_midi\n",
      "  Using cached pretty_midi-0.2.10-py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.7.0 in /opt/anaconda3/lib/python3.11/site-packages (from pretty_midi) (1.26.4)\n",
      "Collecting mido>=1.1.16 (from pretty_midi)\n",
      "  Using cached mido-1.3.2-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.11/site-packages (from pretty_midi) (1.16.0)\n",
      "Requirement already satisfied: packaging~=23.1 in /opt/anaconda3/lib/python3.11/site-packages (from mido>=1.1.16->pretty_midi) (23.1)\n",
      "Using cached mido-1.3.2-py3-none-any.whl (54 kB)\n",
      "Installing collected packages: mido, pretty_midi\n",
      "Successfully installed mido-1.3.2 pretty_midi-0.2.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#function to load midi files from a folder, because of the nesting of the folders  add a root file walk so as to go through the directory \n",
    "def load_midi_files(directory):\n",
    "    midi_files = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.mid'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    midi_files.append(pretty_midi.PrettyMIDI(file_path))\n",
    "                except:\n",
    "                    print(f\"Could not parse {file_path}\")\n",
    "    return midi_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to exttract the notes in a midi file so asto have data points to work with \n",
    "def extract_notes(midi):\n",
    "    notes = []\n",
    "    for instrument in midi.instruments:\n",
    "        if not instrument.is_drum:\n",
    "            for note in instrument.notes:\n",
    "                notes.append((note.start, note.end, note.pitch, note.velocity))\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'instruments'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 64\u001b[0m\n\u001b[1;32m     60\u001b[0m model \u001b[38;5;241m=\u001b[39m load_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/nabilomondi/Documents/Finalproject/my_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Load your data and prepare int_to_note mapping\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Assuming notes and chords have been extracted and converted to integers\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m notes \u001b[38;5;241m=\u001b[39m extract_notes(midi_files)\n\u001b[1;32m     65\u001b[0m pitchnames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mset\u001b[39m(item \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m notes))\n\u001b[1;32m     66\u001b[0m note_to_int \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m((note, number) \u001b[38;5;28;01mfor\u001b[39;00m number, note \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(pitchnames))\n",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m, in \u001b[0;36mextract_notes\u001b[0;34m(midi)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_notes\u001b[39m(midi):\n\u001b[1;32m      3\u001b[0m     notes \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m instrument \u001b[38;5;129;01min\u001b[39;00m midi\u001b[38;5;241m.\u001b[39minstruments:\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m instrument\u001b[38;5;241m.\u001b[39mis_drum:\n\u001b[1;32m      6\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m note \u001b[38;5;129;01min\u001b[39;00m instrument\u001b[38;5;241m.\u001b[39mnotes:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'instruments'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "midi_files = load_midi_files('/Users/nabilomondi/Downloads/Final Project IRONHACK/MIDI FILE/lmd_matched/F/F/A')\n",
    "\n",
    "# Function to map predictions to notes\n",
    "def int_to_note_mapping(predictions, int_to_note):\n",
    "    return [int_to_note[np.argmax(prediction)] for prediction in predictions]\n",
    "\n",
    "# Function to generate music with temperature sampling\n",
    "def generate_music(model, seed_sequence, length, int_to_note, temperature=1.0):\n",
    "    generated = []\n",
    "    current_sequence = seed_sequence\n",
    "    for _ in range(length):\n",
    "        prediction = model.predict(current_sequence.reshape(1, len(current_sequence), 4))[0]\n",
    "\n",
    "        # Apply temperature sampling\n",
    "        prediction = np.log(prediction + 1e-9) / temperature\n",
    "        exp_preds = np.exp(prediction)\n",
    "        prediction = exp_preds / np.sum(exp_preds)\n",
    "\n",
    "        # Sample from the distribution\n",
    "        next_index = np.random.choice(len(prediction), p=prediction)\n",
    "        next_note = int_to_note[next_index]\n",
    "\n",
    "        generated.append(next_note)\n",
    "        next_note_array = np.zeros((1, 4))\n",
    "        next_note_array[0, 0] = next_index\n",
    "        current_sequence = np.vstack([current_sequence[1:], next_note_array])\n",
    "\n",
    "    return generated\n",
    "\n",
    "# Convert generated notes to MIDI file\n",
    "def create_midi(generated_notes, output_file='generated_music.mid'):\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    for pattern in generated_notes:\n",
    "        # Handle chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                new_note = note.Note(int(current_note))\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "        else:\n",
    "            # Handle single note\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        offset += 0.5\n",
    "\n",
    "    midi_stream = midi.stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp=output_file)\n",
    "\n",
    "# Load your trained model\n",
    "model = load_model('/Users/nabilomondi/Documents/Finalproject/my_model.h5')\n",
    "\n",
    "# Load your data and prepare int_to_note mapping\n",
    "# Assuming notes and chords have been extracted and converted to integers\n",
    "notes = notes\n",
    "pitchnames = sorted(set(item for item in notes))\n",
    "note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "\n",
    "# Assuming you have your training data sequences and the model is trained\n",
    "# X = ... # your sequence data here\n",
    "# seed_sequence = X[-2]  # Use the last sequence in the training data as the seed sequence\n",
    "\n",
    "# Generate music\n",
    "generated_notes = generate_music(model, seed_sequence, length=500, int_to_note=int_to_note, temperature=0.8)\n",
    "\n",
    "# Create MIDI file\n",
    "create_midi(generated_notes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
